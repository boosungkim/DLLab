{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOOqfAX3MZxAsGlJSEZ3qU4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boosungkim/ml-paper-implementations/blob/main/vgg_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IgoV-JgJM7cN"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "HmcJZh7TM-hf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "46UzfCL5NAyb",
        "outputId": "7745b63c-f5b9-4df7-c068-31a23f992bf0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 100\n",
        "NUM_EPOCH = 2000\n",
        "NUM_CLASSES = 10\n",
        "CLASSES = ('plane','car','bird','cat','deer',\n",
        "          'dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "id": "iL5EnJfUNBA9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import CIFAR10"
      ],
      "metadata": {
        "id": "CBDvjVkVNB_8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),\n",
        "                        (0.5,0.5,0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "RcpXh68VNDOA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "cifar10_train_dataloader = DataLoader(cifar10_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bC3UcFgNEod",
        "outputId": "865aa7d4-8a6f-4c8b-ced2-beb567036757"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 73064333.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_eval_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "cifar10_val_dataset, cifar10_test_dataset = torch.utils.data.random_split(cifar10_eval_dataset,[0.5,0.5])\n",
        "\n",
        "cifar10_val_dataloader = DataLoader(cifar10_val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "cifar10_test_dataloader = DataLoader(cifar10_test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB6IJ89nNI-B",
        "outputId": "fdd36b89-6492-45a6-9178-9cd29093c3d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, dataloader, criterion, device):\n",
        "    avg_loss = 0.0\n",
        "    avg_acc = 0.0\n",
        "    test_loss = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, (batch_X, batch_y) in enumerate(dataloader):\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            \n",
        "            z = model(batch_X)\n",
        "            \n",
        "            J = criterion(z, batch_y)\n",
        "            test_loss += J.item()\n",
        "            \n",
        "            _, predicted = z.max(1)\n",
        "            test_acc += torch.sum(predicted == batch_y)/len(batch_y)\n",
        "#             print(f\"Batch {i} testing loss: {test_loss}\",\n",
        "#                  f\"Batch {i} testing accuracy: {test_acc}\")\n",
        "            \n",
        "    avg_loss = test_loss / len(dataloader)\n",
        "    avg_acc = test_acc / len(dataloader)\n",
        "    \n",
        "    print(f\"Batch average loss: {avg_loss}\",\n",
        "         f\"Batch average accuracy: {avg_acc}\")\n",
        "            \n",
        "            "
      ],
      "metadata": {
        "id": "b4XsaiaFNFex"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, criterion=None, optimizer=None, scheduler=None, device=DEVICE):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.device = device\n",
        "    \n",
        "    def train_step(self, dataloader):\n",
        "        self.model.train()\n",
        "        step_loss = 0.0\n",
        "        train_predicted = []\n",
        "        train_trues = []\n",
        "        \n",
        "        for i, (batch_X, batch_y) in enumerate(dataloader):\n",
        "            batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            \n",
        "            # forward propagate\n",
        "            z = self.model(batch_X)\n",
        "            \n",
        "            # loss\n",
        "            J = self.criterion(z, batch_y)\n",
        "            step_loss += J.item()\n",
        "            J.backward()\n",
        "            \n",
        "            # backprop\n",
        "            self.optimizer.step()\n",
        "            \n",
        "            # accuracy\n",
        "            _, pred = z.max(1)\n",
        "            train_predicted.extend(pred)\n",
        "            train_trues.extend(batch_y)\n",
        "            \n",
        "        return step_loss, train_predicted, train_trues\n",
        "    \n",
        "    def eval_step(self, dataloader):\n",
        "        self.model.eval()\n",
        "        step_loss = 0.0\n",
        "        val_predicted = []\n",
        "        val_trues = []\n",
        "        \n",
        "        for i, (batch_X, batch_y) in enumerate(dataloader):\n",
        "            batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)\n",
        "            \n",
        "            z = self.model(batch_X)\n",
        "            J = self.criterion(z, batch_y)\n",
        "            step_loss += J.item()\n",
        "            \n",
        "            _, pred = z.max(1)\n",
        "            val_predicted.extend(pred)\n",
        "            val_trues.extend(batch_y)\n",
        "            \n",
        "        return step_loss, val_predicted, val_trues\n",
        "            \n",
        "    \n",
        "    def calc_accuracy(self, predicted_y, true_y):\n",
        "        count = 0\n",
        "        for i, pred in enumerate(predicted_y):\n",
        "            if pred == true_y[i]:\n",
        "                count += 1\n",
        "        return count / len(true_y)\n",
        "    \n",
        "    def train(self, num_epoch, train_dataloader, val_dataloader):\n",
        "        accumulated_loss = 0.0\n",
        "        \n",
        "        for epoch in range(num_epoch):\n",
        "            train_loss, train_predicted, train_trues = self.train_step(train_dataloader)\n",
        "            val_loss, val_predicted, val_trues = self.eval_step(val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "            \n",
        "            accumulated_loss += train_loss\n",
        "            accuracy_train = self.calc_accuracy(train_predicted, train_trues)\n",
        "            accuracy_val = self.calc_accuracy(val_predicted, val_trues)\n",
        "            \n",
        "            \n",
        "            print(f\"--- For epoch {epoch} ---\\n\"\n",
        "                  f\"Average train loss: {train_loss} | Average validation loss: {val_loss}\\n\"\n",
        "                  f\"Train accuracy: {accuracy_train} | Validation accuracy: {accuracy_val}\")\n",
        "        \n",
        "        average_loss = accumulated_loss / num_epoch\n",
        "        \n",
        "        return average_loss\n",
        "            \n",
        "    \n",
        "    # def predict(self, test_dataloader):\n",
        "    #     self.model.eval()\n",
        "    #     accuracy = 0.0\n",
        "    #     for i, (batch_X, batch_y) in enumerate(test_dataloader):\n",
        "            \n",
        "    #     return accuracy"
      ],
      "metadata": {
        "id": "GU5FkYVPNHyw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIGURATION = {\n",
        "    \"VGG11\": [\n",
        "        [64,'M'],\n",
        "        [128,'M'],\n",
        "        [256,256,'M'],\n",
        "        [512,512,'M'],\n",
        "        [512,512,'M']\n",
        "    ],\n",
        "    \"VGG13\": [\n",
        "        [64,64,'M'],\n",
        "        [128,128,'M'],\n",
        "        [256,256,'M'],\n",
        "        [512,512,'M'],\n",
        "        [512,512,'M']\n",
        "    ],\n",
        "    \"VGG16\": [\n",
        "        [64,64,'M'],\n",
        "        [128,128,'M'],\n",
        "        [256,256,256,'M'],\n",
        "        [512,512,512,'M'],\n",
        "        [512,512,512,'M']\n",
        "    ],\n",
        "    \"VGG19\": [\n",
        "        [64,64,'M'],\n",
        "        [128,128,'M'],\n",
        "        [256,256,256,256,'M'],\n",
        "        [512,512,512,512,'M'],\n",
        "        [512,512,512,512,'M']\n",
        "    ]\n",
        "}\n",
        "\n",
        "class VGGModel(nn.Module):\n",
        "    # \n",
        "    # Pytorch implementation of the various VGG models from Very Deep Convulutional Networks For Large-Scale Image Recognition\n",
        "    # \n",
        "    def __init__(self, architecture_name, input_width, num_output):\n",
        "        super(VGGModel, self).__init__()\n",
        "        self.architecture = self.create_architecture(CONFIGURATION.get(architecture_name), input_width, num_output)\n",
        "        self.block1 = self.architecture[0]\n",
        "        self.block2 = self.architecture[1]\n",
        "        self.block3 = self.architecture[2]\n",
        "        self.block4 = self.architecture[3]\n",
        "        self.block5 = self.architecture[4]\n",
        "        self.block6 = self.architecture[5]\n",
        "        self.flat = nn.Flatten()\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        z = self.block1(x)\n",
        "        # print(z.size())     # torch.Size([64, 112, 112])\n",
        "        z = self.block2(z)\n",
        "        # print(z.size())     # torch.Size([128, 56, 56])\n",
        "        z = self.block3(z)\n",
        "        # print(z.size())     # torch.Size([256, 28, 28])\n",
        "        z = self.block4(z)\n",
        "        # print(z.size())     # torch.Size([512, 14, 14])\n",
        "        z = self.block5(z)\n",
        "        # print(z.size())     # torch.Size([512, 7, 7])\n",
        "        # z = self.flat(z).reshape(1,-1)\n",
        "        z = self.flat(z)\n",
        "        # print(z.size())\n",
        "        z = self.block6(z)\n",
        "        return z\n",
        "\n",
        "    \n",
        "    def create_architecture(self, architecture, input_width, num_outputs):\n",
        "        \"\"\"\n",
        "        Create the CNN architecture with num_outputs outputs in the end.\n",
        "        \n",
        "        Parameters\n",
        "        -------------\n",
        "        architecture  :   2D list of int and string\n",
        "              Each entry is either the number of filters in the Conv2d layer or an indication\n",
        "              of MaxPool2d\n",
        "        num_outputs   :   int\n",
        "              Number of output classes in the end of the network\n",
        "        \n",
        "        Returns\n",
        "        -------------\n",
        "        blocks_list   :   List of nn.Sequential\n",
        "            List of PyTorch NN sequences, each representing one block\n",
        "        \"\"\"\n",
        "        blocks_list = []\n",
        "        num_next_input_channels = 3\n",
        "        \n",
        "        for block in architecture:\n",
        "            num_next_input_channels, layers = self.create_block(block, num_next_input_channels)\n",
        "            blocks_list.append(layers)\n",
        "        \n",
        "        # Final layer for all VGG models\n",
        "        blocks_list.append(\n",
        "            nn.Sequential(\n",
        "                        nn.Linear(512*int(input_width / 2**5), 4096), # 32 = 2\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(p=0.5),\n",
        "                        nn.Linear(4096,4096),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Dropout(p=0.5),\n",
        "                        nn.Linear(4096, num_outputs),\n",
        "                        # nn.Softmax(dim=1)\n",
        "                        )\n",
        "        )\n",
        "        return blocks_list\n",
        "\n",
        "\n",
        "    def create_block(self, block, num_next_input_channels):\n",
        "        \"\"\"\n",
        "        Create a singular CNN block.\n",
        "        \n",
        "        Parameters\n",
        "        -------------\n",
        "        block   :   1D list of int and string of block\n",
        "            Each entry is either the int of filters in the Conv2d layer or a str indication\n",
        "            of MaxPool2d\n",
        "        n       :   number for channels for the Conv2d layer\n",
        "        'M'     :   MaxPool2d\n",
        "        \n",
        "        Returns\n",
        "        -------------\n",
        "        num_channels    :   int\n",
        "            number of channels outputted and inputted to the next layer\n",
        "        layers          :   nn.Sequential\n",
        "            Pytorch NN sequence for one block\n",
        "        \"\"\"\n",
        "        layers_list = []\n",
        "        num_channels = num_next_input_channels\n",
        "        for layer in block:\n",
        "                if isinstance(layer, int):\n",
        "                    layers_list += [\n",
        "                        nn.Conv2d(in_channels=num_channels, out_channels=layer, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
        "                        nn.ReLU()\n",
        "                    ]\n",
        "                    num_channels = layer\n",
        "                else:\n",
        "                    layers_list += [\n",
        "                        nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "                    ]\n",
        "        layers = nn.Sequential(*layers_list)\n",
        "        return num_channels, layers"
      ],
      "metadata": {
        "id": "_Dgk24ZiNM2W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGGModel(\"VGG11\",32,10).to(DEVICE)"
      ],
      "metadata": {
        "id": "sgS2-Y7kNPUi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005,eps=1e-08, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=3)"
      ],
      "metadata": {
        "id": "BJN3-rCDNSVl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2 = Trainer(model, loss_fn, optimizer, scheduler, DEVICE)"
      ],
      "metadata": {
        "id": "Zbxz2kQkNUp7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2.train(16, cifar10_train_dataloader, cifar10_val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEZcDgQZNW-y",
        "outputId": "6f42bac6-fd5c-4772-a286-3ec1d8634c5b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- For epoch 0 ---\n",
            "Average train loss: 908.963249206543 | Average validation loss: 77.75905442237854\n",
            "Train accuracy: 0.27864 | Validation accuracy: 0.378\n",
            "--- For epoch 1 ---\n",
            "Average train loss: 682.8947247862816 | Average validation loss: 56.72398680448532\n",
            "Train accuracy: 0.48688 | Validation accuracy: 0.5838\n",
            "--- For epoch 2 ---\n",
            "Average train loss: 521.2222071886063 | Average validation loss: 48.46707731485367\n",
            "Train accuracy: 0.63166 | Validation accuracy: 0.6622\n",
            "--- For epoch 3 ---\n",
            "Average train loss: 424.6241908669472 | Average validation loss: 43.871166944503784\n",
            "Train accuracy: 0.70264 | Validation accuracy: 0.6968\n",
            "--- For epoch 4 ---\n",
            "Average train loss: 350.7294847071171 | Average validation loss: 39.46448755264282\n",
            "Train accuracy: 0.75812 | Validation accuracy: 0.7362\n",
            "--- For epoch 5 ---\n",
            "Average train loss: 293.61700278520584 | Average validation loss: 38.54185110330582\n",
            "Train accuracy: 0.79768 | Validation accuracy: 0.7474\n",
            "--- For epoch 6 ---\n",
            "Average train loss: 237.9230199754238 | Average validation loss: 36.46443873643875\n",
            "Train accuracy: 0.8373 | Validation accuracy: 0.767\n",
            "--- For epoch 7 ---\n",
            "Average train loss: 195.20396594703197 | Average validation loss: 40.050218641757965\n",
            "Train accuracy: 0.86742 | Validation accuracy: 0.7784\n",
            "--- For epoch 8 ---\n",
            "Average train loss: 157.61411906033754 | Average validation loss: 39.306021839380264\n",
            "Train accuracy: 0.89302 | Validation accuracy: 0.7754\n",
            "--- For epoch 9 ---\n",
            "Average train loss: 127.5403130799532 | Average validation loss: 40.6306009888649\n",
            "Train accuracy: 0.9156 | Validation accuracy: 0.7808\n",
            "--- For epoch 10 ---\n",
            "Average train loss: 105.17992121353745 | Average validation loss: 43.56579405069351\n",
            "Train accuracy: 0.9291 | Validation accuracy: 0.7756\n",
            "--- For epoch 11 ---\n",
            "Average train loss: 35.94741317490116 | Average validation loss: 48.69030547142029\n",
            "Train accuracy: 0.97786 | Validation accuracy: 0.795\n",
            "--- For epoch 12 ---\n",
            "Average train loss: 15.923989181406796 | Average validation loss: 55.21495673060417\n",
            "Train accuracy: 0.99166 | Validation accuracy: 0.791\n",
            "--- For epoch 13 ---\n",
            "Average train loss: 8.534322507912293 | Average validation loss: 61.772479355335236\n",
            "Train accuracy: 0.99618 | Validation accuracy: 0.7926\n",
            "--- For epoch 14 ---\n",
            "Average train loss: 5.200743976252852 | Average validation loss: 68.42884194850922\n",
            "Train accuracy: 0.99802 | Validation accuracy: 0.7886\n",
            "--- For epoch 15 ---\n",
            "Average train loss: 3.8522967417084146 | Average validation loss: 68.25751626491547\n",
            "Train accuracy: 0.99852 | Validation accuracy: 0.7928\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254.6856852749479"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, dataloader, criterion, device):\n",
        "    avg_loss = 0.0\n",
        "    avg_acc = 0.0\n",
        "    test_loss = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, (batch_X, batch_y) in enumerate(dataloader):\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            \n",
        "            z = model(batch_X)\n",
        "            \n",
        "            J = criterion(z, batch_y)\n",
        "            test_loss += J.item()\n",
        "            \n",
        "            _, predicted = z.max(1)\n",
        "            test_acc += torch.sum(predicted == batch_y)/len(batch_y)\n",
        "#             print(f\"Batch {i} testing loss: {test_loss}\",\n",
        "#                  f\"Batch {i} testing accuracy: {test_acc}\")\n",
        "            \n",
        "    avg_loss = test_loss / len(dataloader)\n",
        "    avg_acc = test_acc / len(dataloader)\n",
        "    \n",
        "    print(f\"Batch average loss: {avg_loss}\",\n",
        "         f\"Batch average accuracy: {avg_acc}\")\n",
        "            \n",
        "            "
      ],
      "metadata": {
        "id": "oRzy9UTnNZWt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn2 = nn.CrossEntropyLoss()\n",
        "eval(model, cifar10_test_dataloader, loss_fn2, DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUxlJOSgBOXy",
        "outputId": "ece1ca65-5c52-4795-f57b-b1f6af0cf1f5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch average loss: 1.5267061829566955 Batch average accuracy: 0.7786000370979309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pretrained model"
      ],
      "metadata": {
        "id": "IdopWiHqCE0p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "exPBo_eKBbt3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}